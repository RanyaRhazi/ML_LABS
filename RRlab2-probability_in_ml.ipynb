{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Lab 2 - Probability in Machine Learning\n\nWelcome to the Probability in Machine Learning Lab! In this lab, we will explore how probability theory plays a crucial role in machine learning. We will start with a simple coin flip example to grasp the basics and then move on to build a Bayesian email classifier. Let's dive in!\n\n## Setting Up the Environment\n\nFirst, let's import the necessary libraries.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "## Part 1: Coin Flip Probability Example\n\n### Objective:\nTo understand basic probability and Python coding through a coin flip example.\n\n### Simulating Coin Flips\nWe will simulate flipping a coin 1000 times.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Simulating 1000 coin flips, 0 for 'tails' and 1 for 'heads'\ncoin_flips = np.random.choice(['heads', 'tails'], size=1000)\ndf_coin = pd.DataFrame({'flip_result': coin_flips})",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "### Analyzing Flip Results\nNow, let's count how many heads and tails we got.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "flip_counts = df_coin['flip_result'].value_counts()\nprint(flip_counts)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "heads    505\ntails    495\nName: flip_result, dtype: int64\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "### Calculating Probabilities\nNext, we will calculate the probability of getting heads or tails.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "p_heads = flip_counts['heads'] / len(df_coin)\np_tails = flip_counts['tails'] / len(df_coin)\nprint(f\"Probability of Heads: {p_heads}\")\nprint(f\"Probability of Tails: {p_tails}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Probability of Heads: 0.505\nProbability of Tails: 0.495\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "## Part 2: Bayesian Email Classifier\n\n### Objective:\nNow, you will build a Bayesian email classifier to differentiate between 'spam' and 'ham' (not spam) emails.\n\n### Task 1: Exploring the Dataset\nFirst, load and explore the dataset. You can either find and use a dataset or use the following code to simulate a sample dataset.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# The following code snippet creates a simulated email classification (spam and not spam) dataset with 1000 data points.\n\nimport pandas as pd\nimport numpy as np\n\n# Sample size\nn_samples = 1000\n\n# Simulating data\nnp.random.seed(42)\ndata = {\n    'email_length': np.random.normal(100, 20, n_samples).astype(int),\n    'contains_free': np.random.choice([0, 1], size=n_samples, p=[0.7, 0.3]),\n    'contains_winner': np.random.choice([0, 1], size=n_samples, p=[0.8, 0.2]),\n    'time_of_day': np.random.choice(['morning', 'afternoon', 'evening', 'night'], n_samples),\n    'label': np.random.choice(['spam', 'ham'], n_samples, p=[0.4, 0.6])\n}\n\ndf = pd.DataFrame(data)\n\n# Saving the dataset\ndf.to_csv('simulated_email_dataset.csv', index=False)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "# Load the dataset (Replace 'path_to_dataset' with the actual file path). You can uncomment the codes below. Notice what `df_emails.head()` is representing.\ndf_emails = pd.read_csv('simulated_email_dataset.csv')\ndf_emails",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "     email_length  contains_free  contains_winner time_of_day label\n0             109              0                0     morning   ham\n1              97              0                0     morning  spam\n2             112              0                0     morning  spam\n3             130              1                0   afternoon   ham\n4              95              0                1   afternoon  spam\n..            ...            ...              ...         ...   ...\n995            94              0                1       night   ham\n996           135              0                0       night  spam\n997           112              0                0     evening  spam\n998            88              0                1   afternoon  spam\n999           111              0                0     evening  spam\n\n[1000 rows x 5 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>email_length</th>\n      <th>contains_free</th>\n      <th>contains_winner</th>\n      <th>time_of_day</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>109</td>\n      <td>0</td>\n      <td>0</td>\n      <td>morning</td>\n      <td>ham</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>97</td>\n      <td>0</td>\n      <td>0</td>\n      <td>morning</td>\n      <td>spam</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>112</td>\n      <td>0</td>\n      <td>0</td>\n      <td>morning</td>\n      <td>spam</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>130</td>\n      <td>1</td>\n      <td>0</td>\n      <td>afternoon</td>\n      <td>ham</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>95</td>\n      <td>0</td>\n      <td>1</td>\n      <td>afternoon</td>\n      <td>spam</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>94</td>\n      <td>0</td>\n      <td>1</td>\n      <td>night</td>\n      <td>ham</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>135</td>\n      <td>0</td>\n      <td>0</td>\n      <td>night</td>\n      <td>spam</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>112</td>\n      <td>0</td>\n      <td>0</td>\n      <td>evening</td>\n      <td>spam</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>88</td>\n      <td>0</td>\n      <td>1</td>\n      <td>afternoon</td>\n      <td>spam</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>111</td>\n      <td>0</td>\n      <td>0</td>\n      <td>evening</td>\n      <td>spam</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows Ã— 5 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": "### Task 2: Data Preprocessing\nYou need to preprocess the data for analysis. This involves normalizing and encoding the features.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Your code for Data Preprocessing goes here\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\nscaler = StandardScaler()\nlabel_encoder = LabelEncoder() # will be used for time of day feature and label\n\ndf_emails['email_length'] = scaler.fit_transform(df_emails[['email_length']])\ndf_emails['time_of_day'] = label_encoder.fit_transform(df_emails['time_of_day'])\n\ndf_emails['label'] = label_encoder.fit_transform(df_emails['label'])\n\ndf_emails.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 27,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   email_length  contains_free  contains_winner  time_of_day  label\n0      0.465685              0                0            2      0\n1     -0.146723              0                0            2      1\n2      0.618787              0                0            2      1\n3      1.537399              1                0            0      0\n4     -0.248791              0                1            0      1",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>email_length</th>\n      <th>contains_free</th>\n      <th>contains_winner</th>\n      <th>time_of_day</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.465685</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.146723</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.618787</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.537399</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.248791</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": "### Task 3: Probability Calculation\nCalculate the probability of spam and ham emails in the dataset.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Your code for calculating the probability of spam and ham emails in the dataset goes here\nspam_emails = df_emails[df_emails['label'] == 1]\nham_emails = df_emails[df_emails['label'] == 0]\n\nprob_spam = len(spam_emails) / len(df_emails)\nprob_ham = len(ham_emails) / len(df_emails)\n\nprint(f\"Probability of Spam emails: {prob_spam:.2%}\")\nprint(f\"Probability of Ham emails: {prob_ham:.2%}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Probability of Spam emails: 40.90%\nProbability of Ham emails: 59.10%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 29
    },
    {
      "cell_type": "markdown",
      "source": "### Task 4: Implementing Bayes' Theorem\nImplement Bayes' Theorem to classify emails as spam or ham.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write a function using Bayes' Theorem for classification\n\nspam_emails = df_emails[df_emails['label'] == 1]\nspam_emails\nham_emails = df_emails[df_emails['label'] == 0]\n\n\ndef calculate_conditional_probability(feature, value, label):\n    subset = df_emails[df_emails['label'] == label]\n    total_label = len(subset)\n    count_feature_value = len(subset[subset[feature] == value])\n    return count_feature_value / total_label\n\nprob_spam = len(spam_emails) / len(df_emails)\nprob_ham = len(ham_emails) / len(df_emails)\ndef classify_email(email):\n    prob_spam_given_email = prob_spam\n    prob_ham_given_email = prob_ham\n\n    for feature in email.index[:-1]:  # exclude the 'label' column\n        value = email[feature]\n\n        prob_spam_given_email *= calculate_conditional_probability(feature, value, 1)\n        prob_ham_given_email *= calculate_conditional_probability(feature, value, 0)\n\n    return int(prob_spam_given_email > prob_ham_given_email)\n\nfirst_email = df_emails.iloc[0]\nclassification_result = classify_email(first_email)\nprint(\"The email is classified as\", 'spam' if classification_result == 1 else 'ham')",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "The email is classified as spam\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 69
    },
    {
      "cell_type": "markdown",
      "source": "### Task 5: Model Testing\nTest the model on a new dataset and evaluate its performance. You can use a subset of the dataset that you created or create a new one.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Split the data into training and testing sets\nfrom sklearn.model_selection import train_test_split\ntrain_data, test_data = train_test_split(df_emails, test_size=0.2, random_state=42)\n\n# Test the model on the testing set\ncorrect_predictions = 0\n\nfor index, email in test_data.iterrows():\n    predicted_label = classify_email(email)\n    actual_label = email['label']\n\n    if predicted_label == actual_label:\n        correct_predictions += 1\n\naccuracy = correct_predictions / len(test_data)\nprint(f\"Accuracy for test set: {accuracy:.2%}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy for test set: 67.00%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 68
    },
    {
      "cell_type": "markdown",
      "source": "### Task 6: Discussion\n1. Which probability distribution would you choose for an email classifier? Explain your answer.\n2. Discuss how Bayesian updating improves the accuracy of the classifier.\n3. What are the limitations of the model built in this lab?\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "- Bernoulli distribution would be a fit choice for an email classifier as we can treat each feature\nas a binary to indicate the presence or absence of particular \"spam\" words in emails.\n\n- Bayesian updating improves accuracy by continuously updating beliefs about email class (spam/not spam) \nbased on observed word evidence, using Bayes' theorem.\n\n- The main limitation is the Naive assumption that the features are independant because it can never be the case in a real-life scenario. Another limitation is  \nIndependence Assumption: Assumes word independence.\nVocabulary Size: May struggle with large vocabularies.\nStatic Model: Doesn't adapt well to language changes.\nImbalanced Data: Bias if classes are imbalanced.\nLack of Context: Doesn't capture word relationships or contextual meaning.\nAssuming features are independent which isnt thecase in real-world scenarios. and unreal data \nmakes the model unsuitable for real use.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Submission\nSubmit a link to your completed Jupyter Notebook file hosted on your private GitHub repository through the submission link in Blackboard.",
      "metadata": {}
    }
  ]
}